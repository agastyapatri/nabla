#   **NABLA**
_Deep Learning from (almost) scratch_

This project exists to make sure that I understand the core concepts of deep learning: **Gradient Descent** and **Backpropagation**. With time, I intend to implement more sophisticated variants of the Neural Network. 

I intend to write the most performant code I can, but that might take a backseat for haphazard - but understandable - implementations.


## **Dev. Notes**
*   `Tensor` datatype is defined. It will wrap around a numpy array, and has the ability to attach to a computational graph
*   `Linear` layer is defined. It will output a vector form of the activations depending on the number of ouptut neurons
*   Backprop is needed
